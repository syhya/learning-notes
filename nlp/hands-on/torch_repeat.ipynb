{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repeat and  repeat_interleave\n",
    "1. repeat 的功能和行为\n",
    "- 功能: 按照指定的维度重复整个张量。\n",
    "- 行为: 它会根据传入的参数，在每个维度上重复整个张量的内容。\n",
    "- 适用场景: 需要扩展张量的维度或重复张量的整体内容。\n",
    "- tensor.repeat(*sizes) : sizes: 一个整数序列，表示每个维度上重复的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "# 原始张量形状: (2, 2)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6])\n",
      "tensor([[1, 2, 1, 2, 1, 2],\n",
      "        [3, 4, 3, 4, 3, 4],\n",
      "        [1, 2, 1, 2, 1, 2],\n",
      "        [3, 4, 3, 4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 在第一个维度重复2次，第二个维度重复3次\n",
    "y = x.repeat(2, 3)\n",
    "# 结果张量形状: (4, 6)\n",
    "print(y.size())\n",
    "print(y)\n",
    "# 输出:\n",
    "# tensor([[1, 2, 1, 2, 1, 2],\n",
    "#         [3, 4, 3, 4, 3, 4],\n",
    "#         [1, 2, 1, 2, 1, 2],\n",
    "#         [3, 4, 3, 4, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(1, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3],\n",
       "         [1, 2, 3, 1, 2, 3]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(2, 4)\n",
    "\n",
    "\n",
    "# 1. 沿着某个维度复制\n",
    "x.repeat(1, 1).size()  # torch.Size([2, 4])\n",
    "\n",
    "x.repeat(2, 1).size()  # torch.Size([4, 4])\n",
    "\n",
    "x.repeat(1, 2).size()  # torch.Size([2, 8])\n",
    "\n",
    "\n",
    "# 2. 不仅可以复制维度, 还可以拓展维度\n",
    "x.repeat(1, 1, 1).size()  # torch.Size([1, 2, 4])\n",
    "\n",
    "x.repeat(2, 1, 1).size()  # torch.Size([2, 2, 4])\n",
    "\n",
    "x.repeat(1, 1, 1, 1).size()  # torch.Size([1, 1, 2, 4])\n",
    "\n",
    "\n",
    "# 3. repeat中传入的参数不可以少于x的维度\n",
    "try:\n",
    "    x.repeat(1)  # 报错\n",
    "except:\n",
    "    print(\" Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. repeat_interleave 的功能和行为\n",
    "- 功能: 沿着指定的维度逐元素重复张量的元素。\n",
    "- 行为: 针对张量的元素逐一操作，按照指定的次数重复每个元素。\n",
    "- 适用场景: 需要在元素级别对张量进行重复操作。\n",
    "\n",
    "- tensor.repeat_interleave(repeats, dim=None)\n",
    ">repeats: 表示每个元素重复的次数，可以是一个整数或者一个与输入张量沿着 dim 的长度一致的张量。\n",
    ">dim: 指定操作的维度（如果为 None，则会将张量展平成 1D 后再操作）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = x.repeat_interleave(2)\n",
    "# 输出: tensor([1, 1, 2, 2, 3, 3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = x.repeat_interleave(2, dim=0)\n",
    "# 输出: tensor([[1, 2],\n",
    "#               [1, 2],\n",
    "#               [3, 4],\n",
    "#               [3, 4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = x.repeat_interleave(torch.tensor([1, 2, 3]))\n",
    "# 输出: tensor([1, 2, 2, 3, 3, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch.repeat更像是把tensor作为一个整体进行复制, 而torch.repeat_interleave更是针对tensor里的每个元素进行复制，并且torch.repeat_interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.7303e-01, -1.8239e+00,  1.9584e+00, -2.2530e-03, -8.8339e-01,\n",
      "           9.2922e-01, -4.7529e-01, -1.1302e+00,  2.1548e+00, -8.1080e-01,\n",
      "          -6.5028e-01, -6.4566e-01,  3.0621e-01, -1.5821e+00, -8.5193e-01,\n",
      "           6.4006e-01],\n",
      "         [ 8.3008e-02, -4.3098e-01, -2.5415e-01, -8.7879e-01,  2.6055e-01,\n",
      "          -1.8584e+00, -3.7619e-01,  2.9879e-02, -2.8062e-01,  9.4475e-01,\n",
      "          -4.5170e-01,  2.9434e-01, -2.7260e+00, -2.0521e+00,  8.5321e-01,\n",
      "           1.3162e-01],\n",
      "         [ 1.8363e-01,  3.2655e-01,  1.5937e+00, -3.9529e-01,  2.8868e-01,\n",
      "           9.9687e-01,  1.5748e+00, -2.6170e+00,  1.1463e+00,  6.1534e-01,\n",
      "           7.3145e-01,  1.3536e+00,  1.9973e-01, -5.2553e-01,  1.1811e+00,\n",
      "           1.0703e+00],\n",
      "         [-9.1731e-01, -1.2991e-01, -1.0641e+00,  1.6550e+00, -1.4841e-01,\n",
      "           8.4696e-01, -8.6567e-01,  1.4960e+00,  9.6555e-01, -1.3881e+00,\n",
      "          -1.3883e+00, -1.3867e+00,  1.9253e+00, -2.5985e-01,  5.9407e-01,\n",
      "           8.0398e-01],\n",
      "         [ 1.3890e+00,  1.4452e-01, -2.2901e+00,  3.5464e-01,  7.4850e-01,\n",
      "          -5.8681e-01,  6.8203e-01,  1.9862e-01, -4.1585e-01,  6.7949e-01,\n",
      "          -5.4465e-01, -1.0413e+00,  6.4582e-01, -1.4595e+00, -8.9406e-02,\n",
      "           1.5048e+00]],\n",
      "\n",
      "        [[-2.3860e-01, -1.0905e+00,  3.5069e-01,  9.8285e-01,  2.2690e-01,\n",
      "          -1.2663e+00, -2.5649e+00,  1.9897e+00,  1.1645e+00, -4.6675e-01,\n",
      "           2.3337e-01, -4.6876e-01, -1.8214e-01, -1.3994e-03, -1.1387e-01,\n",
      "           1.0973e+00],\n",
      "         [-1.0577e+00,  9.0022e-01, -7.3844e-01,  2.0136e-01, -2.6044e-01,\n",
      "           1.0053e+00,  4.3380e-01,  2.9745e-02, -1.6195e+00,  1.9769e+00,\n",
      "          -3.9388e-01,  2.0043e+00, -9.2218e-01,  3.6350e-01,  7.0237e-01,\n",
      "          -9.5410e-01],\n",
      "         [-1.0746e+00,  6.6898e-02,  1.0133e+00,  4.1965e-01,  1.7336e-01,\n",
      "           8.4422e-01,  1.2857e+00,  7.9477e-01,  2.4993e-01,  7.9915e-01,\n",
      "          -1.1199e+00,  8.4371e-01,  9.2362e-01,  1.7895e+00,  1.0632e+00,\n",
      "           5.8826e-01],\n",
      "         [ 7.6794e-01, -2.7116e-01,  8.3236e-01,  1.7184e-01, -1.2768e+00,\n",
      "          -6.6362e-01,  3.7480e-01,  2.3986e+00,  1.5373e+00,  5.5716e-01,\n",
      "           3.6377e-01,  1.5317e+00,  7.6018e-02,  1.2239e+00,  5.7017e-02,\n",
      "          -6.5199e-01],\n",
      "         [-7.4393e-01, -2.3460e-01,  1.5874e+00,  2.6247e-01,  1.4892e+00,\n",
      "           6.1762e-01,  6.5595e-03,  2.1134e-01, -7.0929e-01,  4.2653e-01,\n",
      "           8.6330e-01,  5.6287e-01, -1.2036e+00, -5.6187e-01,  2.3277e-01,\n",
      "          -6.0115e-02]],\n",
      "\n",
      "        [[-3.8745e-01, -1.6033e-01,  9.6723e-01, -1.2475e+00,  7.1862e-01,\n",
      "          -2.0158e-01, -1.6135e+00, -2.9462e+00,  9.6495e-01, -2.3742e-01,\n",
      "          -1.1151e-01,  1.7336e+00, -2.5860e+00, -2.9245e-01,  7.0939e-01,\n",
      "          -9.3120e-01],\n",
      "         [-1.2928e+00,  4.7924e-01,  5.5916e-01, -3.9268e-01,  2.4914e-01,\n",
      "           5.5343e-01, -1.3671e+00, -5.4903e-01,  8.6947e-01, -8.0334e-01,\n",
      "           1.6435e-01, -7.5843e-01, -3.3128e-01,  2.3529e-01, -5.9089e-01,\n",
      "           2.1141e+00],\n",
      "         [ 2.0941e-01,  4.2003e-01,  2.2253e+00, -6.4263e-01,  1.8778e-01,\n",
      "          -3.2500e-01,  1.0312e+00, -1.9502e-01, -1.3285e-01, -6.1960e-01,\n",
      "          -9.0498e-01, -4.6467e-01,  5.0970e-01,  7.2926e-01, -1.9859e-01,\n",
      "          -1.5634e+00],\n",
      "         [-4.7638e-01,  1.7718e-01, -3.2484e-01, -1.5858e+00, -1.3527e+00,\n",
      "           6.1259e-01, -4.6643e-01, -1.2408e-01, -1.6814e+00,  5.7947e-01,\n",
      "          -3.2535e-01,  5.6215e-01,  1.6449e+00, -6.7328e-01,  4.7929e-01,\n",
      "          -9.1995e-01],\n",
      "         [ 5.7526e-01, -8.6764e-01,  6.2446e-01,  2.5534e+00,  8.0641e-01,\n",
      "          -5.3351e-01, -1.4536e+00,  1.2747e+00, -1.6699e-01,  1.3848e-02,\n",
      "          -1.9321e+00, -1.2081e+00,  8.0234e-01,  1.3968e-01,  2.8060e-01,\n",
      "           1.9468e+00]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# (batch_size, seq_len, hidden_dim)\n",
    "x = torch.randn(3, 5, 16)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_dim is 2\n",
      "q_head_per_group is 4\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, hidden_dim = x.size()\n",
    "nums_head = 8\n",
    "nums_kv_head = 2\n",
    "head_dim = hidden_dim // nums_head\n",
    "print(f\"head_dim is {head_dim}\")\n",
    "q_head_per_group =  nums_head // nums_kv_head\n",
    "print(f\"q_head_per_group is {q_head_per_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_proj = nn.Linear(hidden_dim, nums_kv_head * head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4988,  0.0158,  0.4679, -0.0306],\n",
       "         [ 0.6421, -0.6273,  0.9947, -0.0307],\n",
       "         [ 0.7347,  0.4412, -1.0284,  0.1776],\n",
       "         [-1.2146, -0.1403, -0.3550,  0.8192],\n",
       "         [ 0.2173,  0.0952, -0.6068,  0.5387]],\n",
       "\n",
       "        [[-0.8430, -0.9999,  0.8334, -0.1843],\n",
       "         [ 0.4935,  1.0690, -0.4226,  0.3500],\n",
       "         [-0.3918,  0.8722, -1.6565,  0.7223],\n",
       "         [ 0.0234,  1.0082, -0.4153, -0.6250],\n",
       "         [ 0.1691, -0.5942,  0.0031,  0.5466]],\n",
       "\n",
       "        [[ 0.5519, -0.1868,  1.0101, -0.4999],\n",
       "         [-0.5555, -0.8184, -0.0819,  0.3828],\n",
       "         [-0.3636,  0.0228, -1.0644,  0.4446],\n",
       "         [-0.6011,  0.6844, -0.3876,  0.9775],\n",
       "         [-1.2093, -0.8693, -0.7047,  0.5780]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = q_proj(x)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = q.view(batch_size, seq_len, nums_kv_head, head_dim).transpose(1, 2)\n",
    "# (batch_size, nums_kv_head, seq_len, head_dim)\n",
    "q1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 5, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_repeat = q1.repeat_interleave(q_head_per_group, dim=1)\n",
    "# (batch_size, nums_kv_head, seq_len, head_dim)\n",
    "# -> (batch_size, nums_head, seq_len, head_dim)\n",
    "q1_repeat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4988,  0.0158],\n",
       "          [ 0.6421, -0.6273],\n",
       "          [ 0.7347,  0.4412],\n",
       "          [-1.2146, -0.1403],\n",
       "          [ 0.2173,  0.0952]],\n",
       "\n",
       "         [[-0.4988,  0.0158],\n",
       "          [ 0.6421, -0.6273],\n",
       "          [ 0.7347,  0.4412],\n",
       "          [-1.2146, -0.1403],\n",
       "          [ 0.2173,  0.0952]],\n",
       "\n",
       "         [[-0.4988,  0.0158],\n",
       "          [ 0.6421, -0.6273],\n",
       "          [ 0.7347,  0.4412],\n",
       "          [-1.2146, -0.1403],\n",
       "          [ 0.2173,  0.0952]],\n",
       "\n",
       "         [[-0.4988,  0.0158],\n",
       "          [ 0.6421, -0.6273],\n",
       "          [ 0.7347,  0.4412],\n",
       "          [-1.2146, -0.1403],\n",
       "          [ 0.2173,  0.0952]],\n",
       "\n",
       "         [[ 0.4679, -0.0306],\n",
       "          [ 0.9947, -0.0307],\n",
       "          [-1.0284,  0.1776],\n",
       "          [-0.3550,  0.8192],\n",
       "          [-0.6068,  0.5387]],\n",
       "\n",
       "         [[ 0.4679, -0.0306],\n",
       "          [ 0.9947, -0.0307],\n",
       "          [-1.0284,  0.1776],\n",
       "          [-0.3550,  0.8192],\n",
       "          [-0.6068,  0.5387]],\n",
       "\n",
       "         [[ 0.4679, -0.0306],\n",
       "          [ 0.9947, -0.0307],\n",
       "          [-1.0284,  0.1776],\n",
       "          [-0.3550,  0.8192],\n",
       "          [-0.6068,  0.5387]],\n",
       "\n",
       "         [[ 0.4679, -0.0306],\n",
       "          [ 0.9947, -0.0307],\n",
       "          [-1.0284,  0.1776],\n",
       "          [-0.3550,  0.8192],\n",
       "          [-0.6068,  0.5387]]],\n",
       "\n",
       "\n",
       "        [[[-0.8430, -0.9999],\n",
       "          [ 0.4935,  1.0690],\n",
       "          [-0.3918,  0.8722],\n",
       "          [ 0.0234,  1.0082],\n",
       "          [ 0.1691, -0.5942]],\n",
       "\n",
       "         [[-0.8430, -0.9999],\n",
       "          [ 0.4935,  1.0690],\n",
       "          [-0.3918,  0.8722],\n",
       "          [ 0.0234,  1.0082],\n",
       "          [ 0.1691, -0.5942]],\n",
       "\n",
       "         [[-0.8430, -0.9999],\n",
       "          [ 0.4935,  1.0690],\n",
       "          [-0.3918,  0.8722],\n",
       "          [ 0.0234,  1.0082],\n",
       "          [ 0.1691, -0.5942]],\n",
       "\n",
       "         [[-0.8430, -0.9999],\n",
       "          [ 0.4935,  1.0690],\n",
       "          [-0.3918,  0.8722],\n",
       "          [ 0.0234,  1.0082],\n",
       "          [ 0.1691, -0.5942]],\n",
       "\n",
       "         [[ 0.8334, -0.1843],\n",
       "          [-0.4226,  0.3500],\n",
       "          [-1.6565,  0.7223],\n",
       "          [-0.4153, -0.6250],\n",
       "          [ 0.0031,  0.5466]],\n",
       "\n",
       "         [[ 0.8334, -0.1843],\n",
       "          [-0.4226,  0.3500],\n",
       "          [-1.6565,  0.7223],\n",
       "          [-0.4153, -0.6250],\n",
       "          [ 0.0031,  0.5466]],\n",
       "\n",
       "         [[ 0.8334, -0.1843],\n",
       "          [-0.4226,  0.3500],\n",
       "          [-1.6565,  0.7223],\n",
       "          [-0.4153, -0.6250],\n",
       "          [ 0.0031,  0.5466]],\n",
       "\n",
       "         [[ 0.8334, -0.1843],\n",
       "          [-0.4226,  0.3500],\n",
       "          [-1.6565,  0.7223],\n",
       "          [-0.4153, -0.6250],\n",
       "          [ 0.0031,  0.5466]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5519, -0.1868],\n",
       "          [-0.5555, -0.8184],\n",
       "          [-0.3636,  0.0228],\n",
       "          [-0.6011,  0.6844],\n",
       "          [-1.2093, -0.8693]],\n",
       "\n",
       "         [[ 0.5519, -0.1868],\n",
       "          [-0.5555, -0.8184],\n",
       "          [-0.3636,  0.0228],\n",
       "          [-0.6011,  0.6844],\n",
       "          [-1.2093, -0.8693]],\n",
       "\n",
       "         [[ 0.5519, -0.1868],\n",
       "          [-0.5555, -0.8184],\n",
       "          [-0.3636,  0.0228],\n",
       "          [-0.6011,  0.6844],\n",
       "          [-1.2093, -0.8693]],\n",
       "\n",
       "         [[ 0.5519, -0.1868],\n",
       "          [-0.5555, -0.8184],\n",
       "          [-0.3636,  0.0228],\n",
       "          [-0.6011,  0.6844],\n",
       "          [-1.2093, -0.8693]],\n",
       "\n",
       "         [[ 1.0101, -0.4999],\n",
       "          [-0.0819,  0.3828],\n",
       "          [-1.0644,  0.4446],\n",
       "          [-0.3876,  0.9775],\n",
       "          [-0.7047,  0.5780]],\n",
       "\n",
       "         [[ 1.0101, -0.4999],\n",
       "          [-0.0819,  0.3828],\n",
       "          [-1.0644,  0.4446],\n",
       "          [-0.3876,  0.9775],\n",
       "          [-0.7047,  0.5780]],\n",
       "\n",
       "         [[ 1.0101, -0.4999],\n",
       "          [-0.0819,  0.3828],\n",
       "          [-1.0644,  0.4446],\n",
       "          [-0.3876,  0.9775],\n",
       "          [-0.7047,  0.5780]],\n",
       "\n",
       "         [[ 1.0101, -0.4999],\n",
       "          [-0.0819,  0.3828],\n",
       "          [-1.0644,  0.4446],\n",
       "          [-0.3876,  0.9775],\n",
       "          [-0.7047,  0.5780]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1472, -0.5490],\n",
      "        [-0.1472, -0.5490],\n",
      "        [ 0.0124,  1.0488],\n",
      "        [ 0.0124,  1.0488]])\n"
     ]
    }
   ],
   "source": [
    "print(x.repeat_interleave(2, dim=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
